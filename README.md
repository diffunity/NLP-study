# Natural Language Processing (NLP)
Natural Language Processing (NLP) related studies and practice
##  Papers

#### Word embeddings

- [Efficient Representation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)

- [Ditributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)

- [Word2Vec](https://arxiv.org/pdf/1301.3781.pdf)

- [FastText](https://arxiv.org/pdf/1607.04606.pdf)

- [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf) 


#### Sentence embeddings

- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)

- [Text Understanding with the Attention Sum Reader Network](https://arxiv.org/abs/1603.01547) 

- ELMo | [Deep Contextualized Word Representations](https://arxiv.org/abs/1802.05365)

- Transformer | [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)

- T5 | [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683.pdf)

- CTRL | [A Conditional Transformer Language Model For Controllable Generation](https://arxiv.org/pdf/1909.05858.pdf)

- OpenAI GPT | [Improving Language Understanding by Generative Pre-Training](https://pdfs.semanticscholar.org/cd18/800a0fe0b668a1cc19f2ec95b5003d0a5035.pdf?_ga=2.40131109.647956165.1588658157-925505706.1588658157)

- BERT | [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

- RoBERTa | [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/pdf/1907.11692.pdf)

- ALBERT | [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/pdf/1909.11942.pdf)

- XLNet | [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/pdf/1906.08237.pdf)


#### Others

- [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](https://arxiv.org/abs/1705.02364)

- [Adversarial Multi-task Learning for Text Classification](https://arxiv.org/abs/1704.05742) 

- [GECToR: Grammatical Error Correction: Tag, Not Rewrite](https://arxiv.org/pdf/2005.12592.pdf)

- [Graph Convolutional Networks for Text Classification](https://arxiv.org/pdf/1809.05679.pdf)
    - tf2 implementation [link here](https://github.com/diffunity/misc-studies/tree/master/GNN)

##  Libraries
* Pytorch (1.5.x)
* Tensorflow (2.x.x)
* transformers (3.x.x)
* nltk

## Datasets
* [Big Bad NLP database](https://datasets.quantumstat.com/)

